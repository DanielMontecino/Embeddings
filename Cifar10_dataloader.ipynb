{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import itertools as it\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers, Input\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")\n",
    " \n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "# x_train - training data(images), y_train - labels(digits)\n",
    "print(x_train.shape, x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    ''' Object to train siamese Network with TripletLoss.\n",
    "    It yields a generator that deliver the batches of dataset,\n",
    "    this batches are formed with a specific unmber of clases (ids), \n",
    "    and a given number of images por class, so the batch size depends on\n",
    "    both.\n",
    "    \n",
    "    To generate the batch samples, instead of go over all images, go over \n",
    "    the classes, choosing a determinated number of random samples of each class.\n",
    "    \n",
    "    Contructor args:\n",
    "        images_txt:     Text File where the images's paths are stored (in the common\n",
    "                        format).\n",
    "        ims_per_id:     Number of imagenes per id (or class).\n",
    "        ids_per_batch:  Number of ids or classes in each batch.\n",
    "                        So, batch size = ims_per_id * ids_per_batch\n",
    "    Generates:\n",
    "        im_dict:        A dictionary with tha data, where the keys are the classes\n",
    "                        and the values, a list of the images's paths of the same class.\n",
    "        ids_to_train:   A list with the classes that haven't be used in the actual epoch.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, DATA, ims_per_id = 4, ids_per_batch = 3, shuffle = True,\n",
    "                seed=2017, target_image_size=(32, 32), data_gen_args={}, num_clases=10):\n",
    "        self.ims_per_id = ims_per_id\n",
    "        self.ids_per_batch = ids_per_batch\n",
    "        self.batch_size = ims_per_id * ids_per_batch\n",
    "        self.im_size = target_image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.num_classes = num_clases\n",
    "        self.data_gen_args = data_gen_args\n",
    "        self.train_dict = {}\n",
    "        self.test_dict = {}\n",
    "        self.labels_list = []\n",
    "        \n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = DATA\n",
    "        self.preprocess()\n",
    "        self.set_labels_list()\n",
    "        self.train_dict = self.set_dict(self.y_train)\n",
    "        self.test_dict = self.set_dict(self.y_test)\n",
    "        \n",
    "    def preprocess(self):\n",
    "        self.x_train = self.x_train.astype('float32') / 255.\n",
    "        self.x_test = self.x_test.astype('float32') / 255.\n",
    "        self.y_train = self.y_train.reshape(-1)\n",
    "        self.y_test = self.y_test.reshape(-1)\n",
    "\n",
    "    def set_labels_list(self):\n",
    "        '''\n",
    "        Set the list with the labels, assuming that are the same in test and in train\n",
    "        :return: \n",
    "        '''\n",
    "        self.labels_list = []\n",
    "        for y in self.y_train:\n",
    "            if y not in self.labels_list:\n",
    "                self.labels_list.append(y)\n",
    "                if len(self.labels_list)==self.num_classes:\n",
    "                    break\n",
    "                    \n",
    "    def set_dict(self, y):\n",
    "        final_dict = {}\n",
    "        indices = np.linspace(0, len(y)-1, len(y), dtype=int)\n",
    "        for label in self.labels_list:\n",
    "            label_indices = indices[[y==label]]\n",
    "            final_dict[label] = list(label_indices)\n",
    "        return final_dict\n",
    "                       \n",
    "    def get_total_steps(self):\n",
    "        return len(self.y_train) / self.batch_size\n",
    "       \n",
    "    @staticmethod \n",
    "    def copy_dict(original_dict):\n",
    "        ''' Copy a dict to another, because the only assignment =,\n",
    "        implies that changes in one dict affect the other.\n",
    "        \n",
    "        Input:\n",
    "            original_dict:  The Dictionary to copy.\n",
    "        Output:\n",
    "            new_dict:       The new dictionary, identicall to the\n",
    "                            original'''\n",
    "        new_dict = {}\n",
    "        for key, items in original_dict.items():\n",
    "            new_dict[key] = items.copy()\n",
    "        return new_dict\n",
    "                   \n",
    "    def get_generator(self):\n",
    "        ids_to_train = self.labels_list.copy()\n",
    "        shuffle(ids_to_train)\n",
    "        dict_to_train = self.copy_dict(self.train_dict)\n",
    "        while True:\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            print('normal', len(ids_to_train), self.ids_per_batch)\n",
    "            if len(ids_to_train) < self.ids_per_batch:\n",
    "                ids_to_train = self.labels_list.copy()\n",
    "                shuffle(ids_to_train)\n",
    "                print('reset', len(ids_to_train), self.ids_per_batch)\n",
    "            for _ in range(self.ids_per_batch):\n",
    "                id_ = ids_to_train.pop()\n",
    "                print('1 element poped:', len(ids_to_train))\n",
    "                if len(dict_to_train[id_])<self.ims_per_id:\n",
    "                    dict_to_train[id_] = self.train_dict[id_].copy()\n",
    "                    shuffle(dict_to_train[id_])\n",
    "                for im in range(self.ims_per_id):\n",
    "                    im_id = dict_to_train[id_].pop()\n",
    "                    x_batch.append(self.x_train[im_id])\n",
    "                    y_batch.append(id_)\n",
    "                    \n",
    "            x_batch = np.stack(x_batch, axis = 0)\n",
    "            datagen = ImageDataGenerator(**self.data_gen_args)\n",
    "            datagen.fit(x_batch)\n",
    "            x_batch = next(datagen.flow(x_batch, shuffle=False))\n",
    "            yield x_batch, np.array(y_batch).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def batch_generator(img_dir_path, df, label_map, batch_size=32, shuffle=True,\n",
    "                    seed=2017, target_image_size=(224, 224),\n",
    "                    process_target=True, number_of_batches=None,\n",
    "                    add_seed_shuffle=True, data_gen_args={}, cv2_read=True,\n",
    "                    preprocess_unit=False):\n",
    "    \"\"\"Batch generator for keras model.\"\"\"\n",
    "    if number_of_batches is None:\n",
    "        number_of_batches = np.ceil(df.shape[0] / batch_size)\n",
    "        print(number_of_batches)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        df = df.sample(frac=1)\n",
    "\n",
    "    while True:\n",
    "        if process_target:\n",
    "            y_batch = []\n",
    "\n",
    "        idx_start = batch_size * counter\n",
    "        idx_end = batch_size * (counter + 1)\n",
    "        x_batch = []\n",
    "\n",
    "        for f, tags in df.iloc[idx_start:idx_end].values:\n",
    "            img_path = os.path.join(img_dir_path, '{}.jpg'.format(f))\n",
    "            if cv2_read:\n",
    "                img = cv2.imread(img_path)\n",
    "                x = cv2.resize(img, target_image_size)\n",
    "            else:\n",
    "                img = image.load_img(img_path, target_size=target_image_size)\n",
    "                x = image.img_to_array(img)\n",
    "\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            if preprocess_unit:\n",
    "                x = preprocess_input(x)\n",
    "\n",
    "            x_batch.append(x)\n",
    "\n",
    "            if process_target:\n",
    "                targets = np.zeros(17)\n",
    "                for t in tags.split(' '):\n",
    "                    targets[label_map[t]] = 1\n",
    "                y_batch.append(targets)\n",
    "\n",
    "        x_batch = np.concatenate(x_batch)\n",
    "\n",
    "        datagen = ImageDataGenerator(**data_gen_args)\n",
    "        datagen.fit(x_batch)\n",
    "        x_batch = next(datagen.flow(x_batch, shuffle=False))\n",
    "\n",
    "        counter += 1\n",
    "        if process_target:\n",
    "            yield x_batch, np.array(y_batch)\n",
    "        else:\n",
    "            yield x_batch\n",
    "\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                if add_seed_shuffle:\n",
    "                    np.random.seed(seed + 1)\n",
    "                df = df.sample(frac=1)\n",
    "            counter = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
